{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bigdl.util.common import * \n",
    "from bigdl.transform.vision.image import *\n",
    "from bigdl.transform.vision import image\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from zoo.common.nncontext import *\n",
    "from zoo.pipeline.nnframes.nn_classifier import *\n",
    "from zoo.pipeline.nnframes.nn_image_reader import *\n",
    "from zoo.pipeline.nnframes.nn_image_transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkConf = SparkConf().setAppName(\"ImageTransferLearningExample\")\n",
    "sc = get_nncontext(sparkConf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../../model/bigdl_inception-v1_imagenet_0.4.0.model' \n",
    "preTrainedNNModel = NNModel(Model.loadModel(model_path), [3,224,224]).setPredictionCol(\"embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar xzf flower_photos.tgz\n",
    "!rm flower_photos/LICENSE.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowers():\n",
    "    classes = {}\n",
    "    file_name_set = set()\n",
    "    file_name_class = {}\n",
    "\n",
    "    image_path = 'flower_photos'\n",
    "    for dir_name in os.listdir(image_path):\n",
    "        if os.path.isdir(image_path + '/' + dir_name):\n",
    "            print(dir_name)\n",
    "            classes.setdefault(dir_name, len(classes) + 1)\n",
    "            for file_name in os.listdir(image_path + '/' + dir_name):\n",
    "                if file_name in file_name_set:\n",
    "                    print('Duplicate file name', file_name)\n",
    "                file_name_set.add(file_name)\n",
    "                file_name_class[file_name] = classes[dir_name]\n",
    "            \n",
    "    return classes, file_name_class\n",
    "\n",
    "classes, file_name_class = flowers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'flower_photos/*/*'\n",
    "image_path = data_path\n",
    "imageDF = NNImageReader.readImages(image_path, sc).repartition(12).cache()\n",
    "print (\"partition number: \", imageDF.rdd.getNumPartitions())\n",
    "print (\"image number: \", imageDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(data_path + '/train_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create array of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_classes(csv_file_name):\n",
    "    image_to_class = {}\n",
    "    with open(csv_file_name, 'rt') as f:\n",
    "        line = f.readline() # Skip header\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            name, cls = tuple(line.split(','))\n",
    "            image_to_class.setdefault(name, cls)\n",
    "    return image_to_class\n",
    "\n",
    "train_image_to_class = load_image_classes( data_path + '/train.csv')\n",
    "            \n",
    "vals = set(train_image_to_class.values())\n",
    "classes = {}\n",
    "for v in vals:\n",
    "    classes.setdefault(v, float(len(classes) + 1))\n",
    "    \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getName = udf(lambda row: row[0].split('/')[-1])\n",
    "getLabel = udf(lambda name: classes[train_image_to_class[name.split('.')[0]]], DoubleType())\n",
    "labelDF = imageDF \\\n",
    "    .withColumn(\"name\", getName(col(\"image\"))) \\\n",
    "    .withColumn(\"label\", getLabel(col('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingDF, validationDF) = labelDF.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = NNImageTransformer(\n",
    "    image.Pipeline([Resize(256, 256), \n",
    "                    CenterCrop(224, 224), \n",
    "                    ChannelNormalize(123.0, 117.0, 104.0)])). \\\n",
    "        setInputCol(\"image\"). \\\n",
    "        setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = transformer.transform(trainingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingEmbedDF = preTrainedNNModel.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingEmbedDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.optim.optimizer import Optimizer, Adam, MaxEpoch, EveryEpoch, Top1Accuracy, \\\n",
    "    TrainSummary, ValidationSummary, SeveralIteration, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = Sequential().add(Linear(1000, len(classes))).add(LogSoftMax())\n",
    "\n",
    "classifier = NNClassifier(lrModel, ClassNLLCriterion(), [1000]) \\\n",
    "        .setOptimMethod(SGD(nesterov=True, momentum=0.9, dampening=0.0)) \\\n",
    "        .setLearningRate(LEARNING_RATE) \\\n",
    "        .setBatchSize(BATCH_SIZE) \\\n",
    "        .setMaxEpoch(EPOCHS) \\\n",
    "        .setFeaturesCol(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(stages=[transformer, preTrainedNNModel, classifier])\n",
    "# pipeline = Pipeline(stages=[transformer, preTrainedNNModel, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_model = classifier.fit(trainingEmbedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainPredictDF = grocery_model.transform(trainingDF)\n",
    "# evaluator.evaluate(trainPredictDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationEmbedDF = preTrainedNNModel.transform(transformer.transform(validationDF))\n",
    "predictionDF = grocery_model.transform(validationEmbedDF).cache()\n",
    "predictionDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(predictionDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
