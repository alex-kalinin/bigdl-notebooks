{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Handwritten Digits with LeNet/BigDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from bigdl.dataset import mnist\n",
    "from bigdl.util.common import init_engine, Sample\n",
    "\n",
    "from bigdl.nn.layer import Linear, SpatialMaxPooling, \\\n",
    "    SpatialConvolution, ReLU, Sequential, Reshape, LogSoftMax\n",
    "    \n",
    "from bigdl.optim.optimizer import Optimizer, Adam, MaxEpoch, EveryEpoch, Top1Accuracy, \\\n",
    "    TrainSummary, ValidationSummary, SeveralIteration, SGD\n",
    "\n",
    "from bigdl.nn.criterion import ClassNLLCriterion, CrossEntropyCriterion\n",
    "from bigdl.util.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beans': 14,\n",
       " 'cake': 16,\n",
       " 'candy': 22,\n",
       " 'cereal': 3,\n",
       " 'chips': 15,\n",
       " 'chocolate': 10,\n",
       " 'coffee': 12,\n",
       " 'corn': 13,\n",
       " 'fish': 4,\n",
       " 'flour': 11,\n",
       " 'honey': 7,\n",
       " 'jam': 20,\n",
       " 'juice': 1,\n",
       " 'milk': 17,\n",
       " 'nuts': 0,\n",
       " 'oil': 9,\n",
       " 'pasta': 5,\n",
       " 'rice': 2,\n",
       " 'soda': 19,\n",
       " 'spices': 23,\n",
       " 'sugar': 6,\n",
       " 'tea': 18,\n",
       " 'tomatosauce': 21,\n",
       " 'vinegar': 8,\n",
       " 'water': 24}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../identify-groceries-a0409a00-8-dataset_dp'\n",
    "\n",
    "def load_image_classes(csv_path):\n",
    "    image_to_class = {}\n",
    "    with open(csv_file_name, 'rt') as f:\n",
    "        line = f.readline() # Skip header\n",
    "        for line in f:\n",
    "            line = line.strip('\\n')\n",
    "            name, cls = tuple(line.split(','))\n",
    "            image_to_class.setdefault(name, cls)\n",
    "    return image_to_class\n",
    "\n",
    "train_image_to_class = load_image_classes( data_path + '/train.csv')\n",
    "            \n",
    "vals = set(train_image_to_class.values())\n",
    "classes = {}\n",
    "for v in vals:\n",
    "    classes.setdefault(v, len(classes))\n",
    "    \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_100a.png'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "train_image_path = data_path + '/train_img'\n",
    "train_file_names = os.listdir(train_image_path)\n",
    "train_file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array([np.array(Image.open(train_image_path + '/' + fname)) for fname in train_file_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([classes[train_image_to_class[fname.split('.')[0]]] for fname in train_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9c47ff334e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "train_size = 0.8 * len(images)\n",
    "train_images = images[:train_size], test_images=images[train_size:]\n",
    "train_labels = labels[:train_size], test_labels=labels[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fcbad55b1150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "train_images.shape, test_images.shape, test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3215,), 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape, train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=1000, linewidth=10000)\n",
    "\n",
    "def display(X, y, n):\n",
    "    pic = X[n].reshape(28, 28)\n",
    "    plt.imshow(pic, cmap='gray')\n",
    "    with pd.option_context(\"display.max_columns\", 1000):\n",
    "        print(n)\n",
    "        print(y[n])\n",
    "        print(pic)\n",
    "    \n",
    "n = np.random.randint(0, train_images.shape[0])\n",
    "display(train_images, train_labels, 3243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_COUNT = len(np.unique(train_labels))\n",
    "assert len(np.unique(train_labels)) == CLASS_COUNT\n",
    "CLASS_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data\n",
    "\n",
    "Data normalization helps the numerical algorithms to converge faster (or at all).\n",
    "Our data is in range [0, 255]; we will normalize it to be in the range [0.1, 0.9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(image_data, labels, min_x=None, max_x=None):\n",
    "    min_x = np.min(image_data) if min_x is None else min_x\n",
    "    max_x = np.max(image_data) if max_x is None else max_x\n",
    "    delta = max_x - min_x\n",
    "    a, b = 0.1, 0.9\n",
    "\n",
    "    rdd_images = sc.parallelize(image_data)\n",
    "    rdd_labels = sc.parallelize(labels)\n",
    "\n",
    "    rdd_sample = rdd_images \\\n",
    "        .zip(rdd_labels) \\\n",
    "        .map(lambda features_labels: \\\n",
    "             Sample.from_ndarray((features_labels[0] - min_x) * (b - a) / delta, features_labels[1] + 1))\n",
    "    return rdd_sample, min_x, max_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data.\n",
    "Use Min/Max normalization to improve convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_norm, min_x, max_x = normalize(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: apply the same Min/Max values from the training set to the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_norm, _, _ = normalize(test_images, test_labels, min_x, max_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_test_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# samples = X_test_norm.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeNet(class_num):\n",
    "    model = Sequential()\n",
    "    model.add(Reshape([1, 28, 28]))\n",
    "    \n",
    "    model.add(SpatialConvolution(1, 6, 5, 5).set_name('conv1'))\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(SpatialMaxPooling(2, 2, 2, 2).set_name('pool1'))\n",
    "    \n",
    "    model.add(SpatialConvolution(6, 16, 5, 5).set_name('conv2'))\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(SpatialMaxPooling(2, 2, 2, 2).set_name('pool2'))\n",
    "    \n",
    "    model.add(Reshape([16 * 4 * 4]))\n",
    "    \n",
    "    model.add(Linear(16 * 4 * 4, 84).set_name('fc1'))\n",
    "    model.add(ReLU())\n",
    "\n",
    "#     model.add(Linear(120, 84).set_name('fc2'))\n",
    "#     model.add(ReLU())\n",
    "\n",
    "    model.add(Linear(84, class_num).set_name('score'))\n",
    "    model.add(LogSoftMax())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model = LeNet(CLASS_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(model=lenet_model, training_rdd=X_train_norm,\n",
    "                      criterion=ClassNLLCriterion(),\n",
    "                      optim_method=SGD(nesterov=True, momentum=0.9, dampening=0.0),\n",
    "                      end_trigger=MaxEpoch(EPOCHS),\n",
    "                      batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the validation logic\n",
    "optimizer.set_validation(batch_size=128, val_rdd=X_test_norm,\n",
    "                         trigger=EveryEpoch(),\n",
    "                         val_method=[Top1Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from os import path\n",
    "\n",
    "LOG_DIR = '/tmp/bigdl_summaries'\n",
    "APP_NAME='lenet5-' # + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "try:\n",
    "    shutil.rmtree('/private' + LOG_DIR + '/' + APP_NAME)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary = TrainSummary(log_dir=LOG_DIR, app_name=APP_NAME)\n",
    "train_summary.set_summary_trigger(\"Parameters\", SeveralIteration(10)) \n",
    "val_summary = ValidationSummary(log_dir=LOG_DIR, app_name=APP_NAME)\n",
    "optimizer.set_train_summary(train_summary)\n",
    "optimizer.set_val_summary(val_summary)\n",
    "print(\"saving logs to \", APP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trained_model = optimizer.optimize()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "predictions = trained_model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = predictions.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_classes = [np.argmax(p) for p in preds]\n",
    "pred_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_letter_predict(pred_classes):\n",
    "    N = test_images.shape[0]\n",
    "    i = random.randint(0, N)\n",
    "    image = test_images[i]\n",
    "    pred = pred_classes[i]\n",
    "    print('Prediction:', pred)\n",
    "    display(test_images, test_labels, i)\n",
    "\n",
    "display_letter_predict(pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem:\n",
    "\n",
    "Find several example from the test prediction where we incorrectly predicted the letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
